{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO5S+E0zUfZJoBdfVvORt+d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nastaran-farhadi/BBAC-with-LLM-in-healthcare/blob/main/BBAC_for_one_user.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpC9lwEinwcc",
        "outputId": "f84b9640-ad38-4fb9-f4e8-1b3d29f35564"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faker pandas\n",
        "from faker import Faker\n",
        "import pandas as pd\n",
        "import random\n",
        "from datetime import datetime, timedelta\n",
        "fake = Faker()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9zaZaiaqtDn",
        "outputId": "d6efb3b4-a0d2-4b5d-a60d-bb1007031246"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faker\n",
            "  Downloading faker-37.0.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.11/dist-packages (from faker) (2025.1)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Downloading faker-37.0.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faker\n",
            "Successfully installed faker-37.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from faker import Faker\n",
        "import random\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Initialize Faker\n",
        "fake = Faker()\n",
        "\n",
        "# Set consistent seed for reproducibility\n",
        "random.seed(42)\n",
        "Faker.seed(42)\n",
        "\n",
        "# --- Static Data ---\n",
        "static_profile = {\n",
        "    'employee_id': 'E-2023',\n",
        "    'name': 'Allison Hill',\n",
        "    'role': 'Doctor',\n",
        "    'department': 'Cardiology',\n",
        "    'access_permissions': {\n",
        "        'allowed_datasets': ['Patient Records'],\n",
        "        'allowed_operations': ['Read', 'Update'],\n",
        "        'data_categories': ['Medical History', 'Treatment Plans']\n",
        "    }\n",
        "}\n",
        "\n",
        "# --- Dynamic Data Generation (10 Days) ---\n",
        "def generate_normal_behavior(base_date):\n",
        "    base_ip = '10.1.1.15 (Internal)'\n",
        "    base_location = 'Main Campus - Cardiology Wing'\n",
        "    normal_access_time = datetime.strptime(\"08:00\", \"%H:%M\").time()\n",
        "\n",
        "    records = []\n",
        "    for day in range(10):\n",
        "        access_date = base_date + timedelta(days=day)\n",
        "        access_time = datetime.combine(access_date, normal_access_time) + timedelta(minutes=random.randint(-15, 15))\n",
        "\n",
        "        record = {\n",
        "            'date': access_date.strftime(\"%Y-%m-%d\"),\n",
        "            'timestamp': access_time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "            'requested_dataset': 'Patient Records',\n",
        "            'requested_operation': random.choices(['Read', 'Update'], weights=[0.85, 0.15])[0],\n",
        "            'access_outcome': 'Granted',\n",
        "            'mfa_failures': random.choices([0, 1], weights=[0.95, 0.05])[0],\n",
        "            'ip_address': base_ip,\n",
        "            'location': base_location,\n",
        "            'behavior_score': calculate_behavior_score(access_time, base_ip)\n",
        "        }\n",
        "\n",
        "        if random.random() < 0.1:\n",
        "            record['timestamp'] = (access_time + timedelta(minutes=random.randint(-30, 30))).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "        records.append(record)\n",
        "\n",
        "    return records\n",
        "\n",
        "def calculate_behavior_score(access_time, ip_address):\n",
        "    score = 0.0\n",
        "    hour = access_time.hour\n",
        "    if 7 <= hour <= 9:\n",
        "        score += 0.0\n",
        "    else:\n",
        "        score += min(abs(hour - 8) * 0.1, 0.5)\n",
        "\n",
        "    if \"Internal\" in ip_address:\n",
        "        score += 0.0\n",
        "    else:\n",
        "        score += 0.3\n",
        "\n",
        "    score += random.uniform(-0.05, 0.05)\n",
        "    return max(0.0, min(round(score, 2), 0.3))\n",
        "\n",
        "# Generate dataset\n",
        "base_date = datetime(2023, 10, 1)\n",
        "dynamic_data = generate_normal_behavior(base_date)\n",
        "historical_df = pd.DataFrame(dynamic_data)\n",
        "\n",
        "# --- Display Results in Requested Format ---\n",
        "print(\"=== Static User Profile ===\")\n",
        "print(f\"Name: {static_profile['name']}\")\n",
        "print(f\"Role: {static_profile['role']} ({static_profile['department']})\")\n",
        "print(\"Permissions:\")\n",
        "print(f\"- Allowed Datasets: {', '.join(static_profile['access_permissions']['allowed_datasets'])}\")\n",
        "print(f\"- Allowed Operations: {', '.join(static_profile['access_permissions']['allowed_operations'])}\")\n",
        "print(f\"- Access Categories: {', '.join(static_profile['access_permissions']['data_categories'])}\")\n",
        "\n",
        "print(\"\\n=== 10-Day Activity Log ===\")\n",
        "print(historical_df.to_string(index=False, justify='left', columns=[\n",
        "    'date', 'timestamp', 'requested_dataset',\n",
        "    'requested_operation', 'access_outcome',\n",
        "    'mfa_failures', 'ip_address', 'location', 'behavior_score'\n",
        "]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfTJAAi33WDa",
        "outputId": "da8fa20b-e8e6-4712-8751-548f1edf7b50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Static User Profile ===\n",
            "Name: Allison Hill\n",
            "Role: Doctor (Cardiology)\n",
            "Permissions:\n",
            "- Allowed Datasets: Patient Records\n",
            "- Allowed Operations: Read, Update\n",
            "- Access Categories: Medical History, Treatment Plans\n",
            "\n",
            "=== 10-Day Activity Log ===\n",
            "date       timestamp           requested_dataset requested_operation access_outcome  mfa_failures ip_address           location                       behavior_score\n",
            "2023-10-01 2023-10-01 08:05:00 Patient Records     Read              Granted        0             10.1.1.15 (Internal) Main Campus - Cardiology Wing 0.00           \n",
            "2023-10-02 2023-10-02 07:48:00 Patient Records     Read              Granted        0             10.1.1.15 (Internal) Main Campus - Cardiology Wing 0.00           \n",
            "2023-10-03 2023-10-03 07:45:00 Patient Records     Read              Granted        0             10.1.1.15 (Internal) Main Campus - Cardiology Wing 0.01           \n",
            "2023-10-04 2023-10-04 08:07:00 Patient Records     Read              Granted        0             10.1.1.15 (Internal) Main Campus - Cardiology Wing 0.00           \n",
            "2023-10-05 2023-10-05 08:10:00 Patient Records   Update              Granted        0             10.1.1.15 (Internal) Main Campus - Cardiology Wing 0.00           \n",
            "2023-10-06 2023-10-06 07:29:00 Patient Records     Read              Granted        1             10.1.1.15 (Internal) Main Campus - Cardiology Wing 0.00           \n",
            "2023-10-07 2023-10-07 07:56:00 Patient Records     Read              Granted        0             10.1.1.15 (Internal) Main Campus - Cardiology Wing 0.03           \n",
            "2023-10-08 2023-10-08 08:02:00 Patient Records     Read              Granted        0             10.1.1.15 (Internal) Main Campus - Cardiology Wing 0.00           \n",
            "2023-10-09 2023-10-09 08:05:00 Patient Records     Read              Granted        0             10.1.1.15 (Internal) Main Campus - Cardiology Wing 0.01           \n",
            "2023-10-10 2023-10-10 07:46:00 Patient Records     Read              Granted        0             10.1.1.15 (Internal) Main Campus - Cardiology Wing 0.05           \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset for access"
      ],
      "metadata": {
        "id": "pBy7oSIqzd-R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "from faker import Faker\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Initialize Faker for generating synthetic data\n",
        "fake = Faker()\n",
        "\n",
        "# Define constants with role-department alignment\n",
        "ROLE_DEPARTMENT_MAP = {\n",
        "    \"Doctor\": [\"Emergency\", \"ICU\", \"Radiology\", \"Surgery\", \"Pediatrics\"],\n",
        "    \"Nurse\": [\"Emergency\", \"ICU\", \"Pediatrics\", \"Surgery\"],\n",
        "    \"Receptionist\": [\"Emergency\", \"Records\", \"Admissions\"],\n",
        "    \"Technician\": [\"Radiology\", \"Laboratory\", \"Pharmacy\"],\n",
        "    \"Admin\": [\"Administration\", \"HR\", \"Records\"]\n",
        "}\n",
        "\n",
        "SENSITIVE_ILLNESSES = [\"HIV\", \"Mental Health Disorder\", \"Substance Abuse\", \"Cancer\"]\n",
        "REGULAR_ILLNESSES = [\"Flu\", \"COVID-19\", \"Broken Bone\", \"Infection\", \"Hypertension\", \"Diabetes\"]\n",
        "\n",
        "# Function to generate employee dataset with access levels\n",
        "def generate_employee_dataset(n):\n",
        "    \"\"\"\n",
        "    Generate employee data with role-based access permissions\n",
        "    \"\"\"\n",
        "    data = []\n",
        "    for _ in range(n):\n",
        "        role = random.choice(list(ROLE_DEPARTMENT_MAP.keys()))\n",
        "        department = random.choice(ROLE_DEPARTMENT_MAP[role])\n",
        "\n",
        "        # Define access permissions\n",
        "        permissions = {\n",
        "            \"patient_data\": {\n",
        "                \"access_level\": \"Full\" if role == \"Doctor\" else \"Limited\",\n",
        "                \"allowed_operations\": [\"Read\", \"Update\"] if role == \"Doctor\" else [\"Read\"]\n",
        "            },\n",
        "            \"employee_data\": {\n",
        "                \"access_level\": \"Admin\" if role == \"Admin\" else \"None\",\n",
        "                \"allowed_operations\": [\"Read\", \"Write\", \"Update\"] if role == \"Admin\" else []\n",
        "            }\n",
        "        }\n",
        "\n",
        "        data.append([\n",
        "            f\"E{random.randint(1, 999):03d}\",\n",
        "            fake.name(),\n",
        "            role,\n",
        "            department,\n",
        "            random.randint(50000, 200000),\n",
        "            fake.address().replace(\"\\n\", \", \"),\n",
        "            fake.phone_number(),\n",
        "            permissions\n",
        "        ])\n",
        "\n",
        "    return pd.DataFrame(data, columns=[\n",
        "        \"Employee_ID\", \"Employee_Name\", \"Role\", \"Department\",\n",
        "        \"Salary\", \"Address\", \"Phone\", \"Access_Permissions\"\n",
        "    ])\n",
        "\n",
        "# Function to generate patient dataset with data sensitivity\n",
        "def generate_patient_dataset(n):\n",
        "    \"\"\"\n",
        "    Generate patient data with medical sensitivity levels\n",
        "    \"\"\"\n",
        "    data = []\n",
        "    for _ in range(n):\n",
        "        is_sensitive = random.random() < 0.2  # 20% sensitive cases\n",
        "        illness = random.choice(SENSITIVE_ILLNESSES if is_sensitive else REGULAR_ILLNESSES)\n",
        "\n",
        "        data.append([\n",
        "            f\"P{random.randint(1, 999):03d}\",\n",
        "            fake.name(),\n",
        "            random.choice([\"Male\", \"Female\"]),\n",
        "            random.randint(1, 100),\n",
        "            fake.address().replace(\"\\n\", \", \"),\n",
        "            fake.phone_number(),\n",
        "            illness,\n",
        "            random.choice([\"Private\", \"Medicare\", \"Medicaid\", \"Self-Pay\"]),\n",
        "            datetime.now() - timedelta(days=random.randint(0, 30)),\n",
        "            random.randint(100, 500),\n",
        "            \"High\" if is_sensitive else \"Normal\"\n",
        "        ])\n",
        "\n",
        "    return pd.DataFrame(data, columns=[\n",
        "        \"Patient_ID\", \"Patient_Name\", \"Gender\", \"Age\",\n",
        "        \"Address\", \"Phone\", \"Illness\", \"Insurance_Type\",\n",
        "        \"Admission_Date\", \"Room_Number\", \"Data_Sensitivity\"\n",
        "    ])\n",
        "\n",
        "# Generate datasets\n",
        "employee_df = generate_employee_dataset(20)\n",
        "patient_df = generate_patient_dataset(20)\n",
        "\n",
        "# Display data\n",
        "print(\"\\nEmployee Data (with Access Permissions):\")\n",
        "print(employee_df.head().to_string(index=False))\n",
        "\n",
        "print(\"\\nPatient Data (with Sensitivity Levels):\")\n",
        "print(patient_df.head().to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HM2PXrt1rt6E",
        "outputId": "e7f97eb1-2366-48e0-9fc4-0e3c29816849"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Employee Data (with Access Permissions):\n",
            "Employee_ID  Employee_Name         Role Department  Salary                                                   Address                Phone                                                                                                                                                           Access_Permissions\n",
            "       E285    Noah Rhodes       Doctor    Surgery  168858             600 Jeffery Parkways, New Jamesside, MT 29394     394.802.6542x351                    {'patient_data': {'access_level': 'Full', 'allowed_operations': ['Read', 'Update']}, 'employee_data': {'access_level': 'None', 'allowed_operations': []}}\n",
            "       E380     Ryan Munoz Receptionist  Emergency  143132   161 Calderon River Suite 931, Lake Jeremyport, CO 31013         664-375-2553                           {'patient_data': {'access_level': 'Limited', 'allowed_operations': ['Read']}, 'employee_data': {'access_level': 'None', 'allowed_operations': []}}\n",
            "       E719 Carolyn Daniel        Nurse Pediatrics   68717          8350 Lydia Valley Suite 641, New Nancy, MD 28370 +1-876-772-4238x8496                           {'patient_data': {'access_level': 'Limited', 'allowed_operations': ['Read']}, 'employee_data': {'access_level': 'None', 'allowed_operations': []}}\n",
            "       E176  Zachary Hicks        Admin    Records  190021                 22691 James Mountain, Tashatown, TX 94967         284-651-4627 {'patient_data': {'access_level': 'Limited', 'allowed_operations': ['Read']}, 'employee_data': {'access_level': 'Admin', 'allowed_operations': ['Read', 'Write', 'Update']}}\n",
            "       E474  Pamela Romero        Nurse        ICU  149471 893 Nathaniel Estates Apt. 957, North Sarahport, IA 08093         991.417.1822                           {'patient_data': {'access_level': 'Limited', 'allowed_operations': ['Read']}, 'employee_data': {'access_level': 'None', 'allowed_operations': []}}\n",
            "\n",
            "Patient Data (with Sensitivity Levels):\n",
            "Patient_ID      Patient_Name Gender  Age                                             Address               Phone         Illness Insurance_Type             Admission_Date  Room_Number Data_Sensitivity\n",
            "      P115    Tamara Hampton Female   56  3147 Karen Port Suite 507, Hunterborough, MI 34363  949-948-0831x36783     Broken Bone       Medicare 2025-03-03 10:38:24.346760          101           Normal\n",
            "      P270     Alan Phillips   Male   65         9578 Coleman Summit, Michaelmouth, KY 40690    631-335-1823x374        Diabetes        Private 2025-02-18 10:38:24.347470          420           Normal\n",
            "      P520    Elizabeth Ward   Male   20             0084 Dana Terrace, Garciatown, OK 37769   277.452.0471x1671        Diabetes       Medicaid 2025-02-21 10:38:24.348104          182           Normal\n",
            "      P941     Justin Torres   Male   77                    Unit 1869 Box 9938, DPO AA 59550    649.364.9909x133    Hypertension       Medicaid 2025-03-02 10:38:24.348565          109           Normal\n",
            "      P900 Christopher Jones Female   31 974 Jesse Squares Suite 713, Kristinshire, TN 26429 (918)332-4210x24994 Substance Abuse        Private 2025-03-10 10:38:24.349205          390             High\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "key pattern of historical dataset of one user"
      ],
      "metadata": {
        "id": "rIuf5_7fy_fw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# --- Hugging Face Embedding Model ---\n",
        "def embed_log_entries_hf(df):\n",
        "    \"\"\"Convert log entries to vector embeddings using Hugging Face\"\"\"\n",
        "    model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "\n",
        "    # Create text representations\n",
        "    df['log_text'] = df.apply(\n",
        "        lambda x: f\"On {x['date']} at {x['timestamp'].time()}, \" +\n",
        "                  f\"{static_profile['name']} performed {x['requested_operation']} \" +\n",
        "                  f\"from {x['location']} (IP: {x['ip_address']}), \" +\n",
        "                  f\"MFA failures: {x['mfa_failures']}, \" +\n",
        "                  f\"Risk score: {x['behavior_score']}\",\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    # Generate embeddings\n",
        "    df['embedding'] = df['log_text'].apply(lambda x: model.encode(x))\n",
        "    return df\n",
        "\n",
        "# Generate embeddings\n",
        "embedded_df = embed_log_entries_hf(historical_df.copy())\n",
        "\n",
        "print(\"\\n=== Embedded Log Entries ===\")\n",
        "print(embedded_df[['log_text', 'embedding']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVYP7C8absnO",
        "outputId": "2d83b81e-a90e-476b-ec6f-f36216c7dd53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Embedded Log Entries ===\n",
            "                                            log_text  \\\n",
            "0  On 2023-10-01 at 08:05:00, Allison Hill perfor...   \n",
            "1  On 2023-10-02 at 07:48:00, Allison Hill perfor...   \n",
            "2  On 2023-10-03 at 07:45:00, Allison Hill perfor...   \n",
            "3  On 2023-10-04 at 08:07:00, Allison Hill perfor...   \n",
            "4  On 2023-10-05 at 08:10:00, Allison Hill perfor...   \n",
            "\n",
            "                                           embedding  \n",
            "0  [-0.029415758, 0.009264707, -0.033427626, 0.02...  \n",
            "1  [-0.031590264, 0.008542097, -0.032836016, 0.02...  \n",
            "2  [-0.029741656, 0.007885972, -0.0342469, 0.0236...  \n",
            "3  [-0.029362421, 0.004619626, -0.030891113, 0.02...  \n",
            "4  [-0.0514411, -0.0012354427, -0.00929477, 0.001...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.docstore.in_memory import InMemoryDocstore\n",
        "from langchain.schema import Document\n",
        "\n",
        "# --- Vector Database with Hugging Face Embeddings ---\n",
        "def create_vector_db_hf(embedded_df):\n",
        "    \"\"\"Store Hugging Face embeddings in a searchable vector database\"\"\"\n",
        "    texts = embedded_df['log_text'].tolist()\n",
        "    embeddings = np.array(embedded_df['embedding'].tolist())\n",
        "\n",
        "    # Create FAISS index\n",
        "    dimension = embeddings.shape[1]  # Get embedding dimension\n",
        "    index = faiss.IndexFlatL2(dimension)  # Create FAISS index\n",
        "    index.add(embeddings.astype('float32'))  # Add embeddings\n",
        "\n",
        "    # Create LangChain FAISS wrapper\n",
        "    vector_db = FAISS(\n",
        "        embedding_function=None,  # Not needed since we have precomputed embeddings\n",
        "        index=index,\n",
        "        docstore=InMemoryDocstore(),\n",
        "        index_to_docstore_id={i: i for i in range(len(texts))}\n",
        "    )\n",
        "\n",
        "    # Add text metadata\n",
        "    for i, text in enumerate(texts):\n",
        "        vector_db.docstore.add({i: Document(page_content=text)})\n",
        "\n",
        "    return vector_db\n",
        "\n",
        "# Create and persist vector DB\n",
        "vector_db = create_vector_db_hf(embedded_df)\n",
        "\n",
        "print(\"\\n=== Vector Database Info ===\")\n",
        "print(f\"Index size: {vector_db.index.ntotal}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6-XndsEbyHg",
        "outputId": "f98ff937-b61e-47ce-c6e3-d1139f560c63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.vectorstores.faiss:`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vector Database Info ===\n",
            "Index size: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_access_request(request, vector_db):\n",
        "    \"\"\"Compare real-time request with historical data\"\"\"\n",
        "    model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "\n",
        "    # Create query text\n",
        "    query_text = (\n",
        "        f\"New access request: {request['operation']} operation \"\n",
        "        f\"on {request['dataset']} at {request['time']} \"\n",
        "        f\"from {request['location']} (IP: {request['ip']}), \"\n",
        "        f\"MFA failures: {request['mfa_failures']}\"\n",
        "    )\n",
        "\n",
        "    # Generate query embedding\n",
        "    query_embedding = model.encode(query_text)\n",
        "\n",
        "    # Search FAISS index\n",
        "    distances, indices = vector_db.index.search(\n",
        "        np.array([query_embedding]).astype('float32'),\n",
        "        k=3\n",
        "    )\n",
        "\n",
        "    # Retrieve matching documents\n",
        "    similar_logs = []\n",
        "    for idx in indices[0]:\n",
        "        doc = vector_db.docstore.get(str(idx))\n",
        "        if isinstance(doc, Document):  # Ensure doc is a Document object\n",
        "            similar_logs.append({\n",
        "                'log': doc.page_content,\n",
        "                'score': float(1 - distances[0][idx])  # Convert distance to similarity\n",
        "            })\n",
        "        else:\n",
        "            print(f\"Warning: Retrieved object is not a Document: {doc}\")\n",
        "\n",
        "    return similar_logs"
      ],
      "metadata": {
        "id": "G7Yje91mnQqM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simulating User Requests"
      ],
      "metadata": {
        "id": "eOWWR7euuAuz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def simulate_real_time_request_from_profile(user_profile, is_suspicious=False):\n",
        "    \"\"\"\n",
        "    Simulate a realtime access request by combining static attributes from the user's profile\n",
        "    with dynamic attributes. The dynamic attributes vary if the request is suspicious.\n",
        "\n",
        "    Parameters:\n",
        "        user_profile (dict): Static user info (e.g., name, role, department, employee_id)\n",
        "        is_suspicious (bool): Flag to indicate if the dynamic attributes should simulate malicious behavior\n",
        "\n",
        "    Returns:\n",
        "        dict: Combined request with both static and dynamic fields.\n",
        "    \"\"\"\n",
        "    # Extract static attributes from the profile\n",
        "    request = {\n",
        "        'employee_id': user_profile.get('employee_id'),\n",
        "        'name': user_profile.get('name'),\n",
        "        'role': user_profile.get('role'),\n",
        "        'department': user_profile.get('department'),\n",
        "        'dataset': 'Patient Records'  # Assuming the dataset is fixed in this example\n",
        "    }\n",
        "\n",
        "    # Add dynamic attributes depending on whether the behavior is suspicious\n",
        "    if is_suspicious:\n",
        "        dynamic_attributes = {\n",
        "            'operation': 'Update',          # Unusual operation compared to typical 'Read'\n",
        "            'time': '02:15:00',             # Unusual access time (early morning)\n",
        "            'location': 'External Clinic',  # Uncommon location for this user\n",
        "            'ip': '203.0.113.5',            # External IP address\n",
        "            'mfa_failures': 2               # Multiple MFA failures indicating risk\n",
        "        }\n",
        "    else:\n",
        "        dynamic_attributes = {\n",
        "            'operation': 'Read',            # Typical operation\n",
        "            'time': '08:10:00',             # Expected access time (around normal schedule)\n",
        "            'location': 'Main Campus - Cardiology Wing',  # Expected location\n",
        "            'ip': '10.1.1.15',              # Internal IP address\n",
        "            'mfa_failures': 0               # No MFA failures\n",
        "        }\n",
        "\n",
        "    # Merge the static and dynamic parts into one request dictionary\n",
        "    request.update(dynamic_attributes)\n",
        "    return request\n",
        "\n",
        "# Example usage:\n",
        "static_profile = {\n",
        "    'employee_id': 'E-2023',\n",
        "    'name': 'Allison Hill',\n",
        "    'role': 'Doctor',\n",
        "    'department': 'Cardiology',\n",
        "    'access_permissions': {\n",
        "        'allowed_datasets': ['Patient Records'],\n",
        "        'allowed_operations': ['Read', 'Update'],\n",
        "        'data_categories': ['Medical History', 'Treatment Plans']\n",
        "    }\n",
        "}\n",
        "\n",
        "normal_request = simulate_real_time_request_from_profile(static_profile, is_suspicious=False)\n",
        "malicious_request = simulate_real_time_request_from_profile(static_profile, is_suspicious=True)\n",
        "\n",
        "print(\"Normal Request:\")\n",
        "print(normal_request)\n",
        "\n",
        "print(\"\\nMalicious Request:\")\n",
        "print(malicious_request)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmAsPg7iwNO1",
        "outputId": "413986bb-3b8f-4b3e-968d-ff14d6842680"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normal Request:\n",
            "{'employee_id': 'E-2023', 'name': 'Allison Hill', 'role': 'Doctor', 'department': 'Cardiology', 'dataset': 'Patient Records', 'operation': 'Read', 'time': '08:10:00', 'location': 'Main Campus - Cardiology Wing', 'ip': '10.1.1.15', 'mfa_failures': 0}\n",
            "\n",
            "Malicious Request:\n",
            "{'employee_id': 'E-2023', 'name': 'Allison Hill', 'role': 'Doctor', 'department': 'Cardiology', 'dataset': 'Patient Records', 'operation': 'Update', 'time': '02:15:00', 'location': 'External Clinic', 'ip': '203.0.113.5', 'mfa_failures': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 2: Convert the request to a textual query ---\n",
        "def request_to_text(request):\n",
        "    \"\"\"\n",
        "    Convert the realtime request dictionary into a descriptive text.\n",
        "    \"\"\"\n",
        "    text = (\n",
        "        f\"On a new access request, {request['name']} ({request['role']} in {request['department']}) \"\n",
        "        f\"performed a {request['operation']} operation on {request['dataset']} at {request['time']}, \"\n",
        "        f\"from {request['location']} (IP: {request['ip']}), with {request['mfa_failures']} MFA failures.\"\n",
        "    )\n",
        "    return text\n",
        "\n",
        "query_text = request_to_text(normal_request)\n",
        "print(\"Query Text:\")\n",
        "print(query_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2spVj-0xHY3",
        "outputId": "3c83ee46-c708-4a83-f2a9-d86f0bc954f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query Text:\n",
            "On a new access request, Allison Hill (Doctor in Cardiology) performed a Read operation on Patient Records at 08:10:00, from Main Campus - Cardiology Wing (IP: 10.1.1.15), with 0 MFA failures.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 3: Embed the query using the same sentence transformer model ---\n",
        "embedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "query_embedding = embedding_model.encode(query_text)\n",
        "\n",
        "# --- Step 4: Retrieve similar historical entries from FAISS vector DB ---\n",
        "# Here we assume that 'vector_db' is your FAISS vector database that has been created earlier.\n",
        "# For this example, we search for the top 3 similar entries.\n",
        "k = 3\n",
        "distances, indices = vector_db.index.search(np.array([query_embedding]).astype('float32'), k=k)\n",
        "\n",
        "# --- Step 5: Retrieve the matching log texts using the docstore ---\n",
        "# (Assuming vector_db.docstore has a dictionary attribute 'docs' mapping indices to Document objects)\n",
        "retrieved_logs = []\n",
        "for idx in indices[0]:\n",
        "    # Access the document from the docstore; adjust as needed based on your implementation.\n",
        "    # For example, if your docstore is a dictionary:\n",
        "    # Ensure the index is within the valid range of your docstore\n",
        "    if 0 <= idx < len(vector_db.docstore._dict):\n",
        "        doc = vector_db.docstore._dict.get(idx)  # using _dict as a common attribute for in-memory storage\n",
        "        if doc is not None:\n",
        "            retrieved_logs.append({\n",
        "                'log': doc.page_content,\n",
        "                'similarity': 1 - distances[0][indices[0].tolist().index(idx)]  # convert distance to similarity (simple inversion)\n",
        "            })"
      ],
      "metadata": {
        "id": "CmRossrExLrr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 6: (Optional) Combine retrieved context with a generative model ---\n",
        "# In a full RAG pipeline, you would now feed the query_text along with the retrieved logs into a language model\n",
        "# to generate a natural language analysis. For this example, we simply print the retrieved logs.\n",
        "print(\"\\n=== Retrieved Historical Entries ===\")\n",
        "for i, entry in enumerate(retrieved_logs, 1):\n",
        "    print(f\"\\nMatch #{i} (Similarity: {entry['similarity']:.2f}):\")\n",
        "    print(entry['log'])\n",
        "\n",
        "# Now, you have compared the normal request with historical data using the RAG approach:\n",
        "# - The query_text represents the new request.\n",
        "# - The FAISS vector search retrieves similar historical log entries.\n",
        "# - In a complete RAG system, the retrieved context and query can be fed into a language model\n",
        "#   to generate an explanation or alert if the new behavior is anomalous."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3Oa0Rg9xjMS",
        "outputId": "84183159-5ebe-451a-c03f-616691a4ea15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Retrieved Historical Entries ===\n",
            "\n",
            "Match #1 (Similarity: 0.72):\n",
            "On 2023-10-07 at 07:56:00, Allison Hill performed Read from Main Campus - Cardiology Wing (IP: 10.1.1.15 (Internal)), MFA failures: 0, Risk score: 0.03\n",
            "\n",
            "Match #2 (Similarity: 0.72):\n",
            "On 2023-10-03 at 07:45:00, Allison Hill performed Read from Main Campus - Cardiology Wing (IP: 10.1.1.15 (Internal)), MFA failures: 0, Risk score: 0.01\n",
            "\n",
            "Match #3 (Similarity: 0.70):\n",
            "On 2023-10-10 at 07:46:00, Allison Hill performed Read from Main Campus - Cardiology Wing (IP: 10.1.1.15 (Internal)), MFA failures: 0, Risk score: 0.05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_access(similar_logs, threshold=0.8):\n",
        "    \"\"\"\n",
        "    Evaluate if a user request should be granted access based on similarity scores.\n",
        "\n",
        "    Parameters:\n",
        "        similar_logs (list): A list of dictionaries from the retrieval function,\n",
        "                             each containing a 'similarity' key.\n",
        "        threshold (float): The minimum average similarity required to grant access.\n",
        "\n",
        "    Returns:\n",
        "        bool: True if access should be granted, False otherwise.\n",
        "    \"\"\"\n",
        "    if not similar_logs:\n",
        "        # No similar historical data found - treat as anomalous\n",
        "        return False\n",
        "\n",
        "    # Calculate the average similarity of the retrieved logs\n",
        "    avg_similarity = sum(entry['similarity'] for entry in similar_logs) / len(similar_logs)\n",
        "    print(f\"Average similarity score: {avg_similarity:.2f}\")\n",
        "\n",
        "    # Grant access if the average similarity meets or exceeds the threshold\n",
        "    return avg_similarity >= threshold\n",
        "\n",
        "# Example usage assuming you have retrieved similar_logs from the FAISS index:\n",
        "# (similar_logs is a list of dictionaries, each with a 'log' and a 'similarity' field)\n",
        "similar_logs = [\n",
        "    {'log': 'Historical log entry 1...', 'similarity': 0.85},\n",
        "    {'log': 'Historical log entry 2...', 'similarity': 0.80},\n",
        "    {'log': 'Historical log entry 3...', 'similarity': 0.78}\n",
        "]\n",
        "\n",
        "access_granted = evaluate_access(similar_logs, threshold=0.8)\n",
        "if access_granted:\n",
        "    print(\"Access Granted.\")\n",
        "else:\n",
        "    print(\"Access Denied. The request does not match historical behavior.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQ5DyrrPyDfs",
        "outputId": "cef9daff-42bc-451c-b224-0841882e58ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average similarity score: 0.81\n",
            "Access Granted.\n"
          ]
        }
      ]
    }
  ]
}