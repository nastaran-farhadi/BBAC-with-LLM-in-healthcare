{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpC9lwEinwcc",
        "outputId": "f84b9640-ad38-4fb9-f4e8-1b3d29f35564"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faker pandas\n",
        "from faker import Faker\n",
        "import pandas as pd\n",
        "import random\n",
        "from datetime import datetime, timedelta\n",
        "fake = Faker()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9zaZaiaqtDn",
        "outputId": "d6efb3b4-a0d2-4b5d-a60d-bb1007031246"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faker\n",
            "  Downloading faker-37.0.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.11/dist-packages (from faker) (2025.1)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Downloading faker-37.0.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faker\n",
            "Successfully installed faker-37.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from faker import Faker\n",
        "import random\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Initialize Faker\n",
        "fake = Faker()\n",
        "\n",
        "# Set consistent seed for reproducibility\n",
        "random.seed(42)\n",
        "Faker.seed(42)\n",
        "\n",
        "# --- Static Data ---\n",
        "static_profile = {\n",
        "    'employee_id': 'E-2023',\n",
        "    'name': 'Allison Hill',\n",
        "    'role': 'Doctor',\n",
        "    'department': 'Cardiology',\n",
        "    'access_permissions': {\n",
        "        'allowed_datasets': ['Patient Records'],\n",
        "        'allowed_operations': ['Read', 'Update'],\n",
        "        'data_categories': ['Medical History', 'Treatment Plans']\n",
        "    }\n",
        "}\n",
        "\n",
        "# --- Dynamic Data Generation (10 Days) ---\n",
        "def generate_normal_behavior(base_date):\n",
        "    base_ip = '10.1.1.15 (Internal)'\n",
        "    base_location = 'Main Campus - Cardiology Wing'\n",
        "    normal_access_time = datetime.strptime(\"08:00\", \"%H:%M\").time()\n",
        "\n",
        "    records = []\n",
        "    for day in range(10):\n",
        "        access_date = base_date + timedelta(days=day)\n",
        "        access_time = datetime.combine(access_date, normal_access_time) + timedelta(minutes=random.randint(-15, 15))\n",
        "\n",
        "        record = {\n",
        "            'date': access_date.strftime(\"%Y-%m-%d\"),\n",
        "            'timestamp': access_time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "            'requested_dataset': 'Patient Records',\n",
        "            'requested_operation': random.choices(['Read', 'Update'], weights=[0.85, 0.15])[0],\n",
        "            'access_outcome': 'Granted',\n",
        "            'mfa_failures': random.choices([0, 1], weights=[0.95, 0.05])[0],\n",
        "            'ip_address': base_ip,\n",
        "            'location': base_location,\n",
        "            'behavior_score': calculate_behavior_score(access_time, base_ip)\n",
        "        }\n",
        "\n",
        "        if random.random() < 0.1:\n",
        "            record['timestamp'] = (access_time + timedelta(minutes=random.randint(-30, 30))).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "        records.append(record)\n",
        "\n",
        "    return records\n",
        "\n",
        "def calculate_behavior_score(access_time, ip_address):\n",
        "    score = 0.0\n",
        "    hour = access_time.hour\n",
        "    if 7 <= hour <= 9:\n",
        "        score += 0.0\n",
        "    else:\n",
        "        score += min(abs(hour - 8) * 0.1, 0.5)\n",
        "\n",
        "    if \"Internal\" in ip_address:\n",
        "        score += 0.0\n",
        "    else:\n",
        "        score += 0.3\n",
        "\n",
        "    score += random.uniform(-0.05, 0.05)\n",
        "    return max(0.0, min(round(score, 2), 0.3))\n",
        "\n",
        "# Generate dataset\n",
        "base_date = datetime(2023, 10, 1)\n",
        "dynamic_data = generate_normal_behavior(base_date)\n",
        "historical_df = pd.DataFrame(dynamic_data)\n",
        "\n",
        "# --- Display Results in Requested Format ---\n",
        "print(\"=== Static User Profile ===\")\n",
        "print(f\"Name: {static_profile['name']}\")\n",
        "print(f\"Role: {static_profile['role']} ({static_profile['department']})\")\n",
        "print(\"Permissions:\")\n",
        "print(f\"- Allowed Datasets: {', '.join(static_profile['access_permissions']['allowed_datasets'])}\")\n",
        "print(f\"- Allowed Operations: {', '.join(static_profile['access_permissions']['allowed_operations'])}\")\n",
        "print(f\"- Access Categories: {', '.join(static_profile['access_permissions']['data_categories'])}\")\n",
        "\n",
        "print(\"\\n=== 10-Day Activity Log ===\")\n",
        "print(historical_df.to_string(index=False, justify='left', columns=[\n",
        "    'date', 'timestamp', 'requested_dataset',\n",
        "    'requested_operation', 'access_outcome',\n",
        "    'mfa_failures', 'ip_address', 'location', 'behavior_score'\n",
        "]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfTJAAi33WDa",
        "outputId": "da8fa20b-e8e6-4712-8751-548f1edf7b50"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Static User Profile ===\n",
            "Name: Allison Hill\n",
            "Role: Doctor (Cardiology)\n",
            "Permissions:\n",
            "- Allowed Datasets: Patient Records\n",
            "- Allowed Operations: Read, Update\n",
            "- Access Categories: Medical History, Treatment Plans\n",
            "\n",
            "=== 10-Day Activity Log ===\n",
            "date       timestamp           requested_dataset requested_operation access_outcome  mfa_failures ip_address           location                       behavior_score\n",
            "2023-10-01 2023-10-01 08:05:00 Patient Records     Read              Granted        0             10.1.1.15 (Internal) Main Campus - Cardiology Wing 0.00           \n",
            "2023-10-02 2023-10-02 07:48:00 Patient Records     Read              Granted        0             10.1.1.15 (Internal) Main Campus - Cardiology Wing 0.00           \n",
            "2023-10-03 2023-10-03 07:45:00 Patient Records     Read              Granted        0             10.1.1.15 (Internal) Main Campus - Cardiology Wing 0.01           \n",
            "2023-10-04 2023-10-04 08:07:00 Patient Records     Read              Granted        0             10.1.1.15 (Internal) Main Campus - Cardiology Wing 0.00           \n",
            "2023-10-05 2023-10-05 08:10:00 Patient Records   Update              Granted        0             10.1.1.15 (Internal) Main Campus - Cardiology Wing 0.00           \n",
            "2023-10-06 2023-10-06 07:29:00 Patient Records     Read              Granted        1             10.1.1.15 (Internal) Main Campus - Cardiology Wing 0.00           \n",
            "2023-10-07 2023-10-07 07:56:00 Patient Records     Read              Granted        0             10.1.1.15 (Internal) Main Campus - Cardiology Wing 0.03           \n",
            "2023-10-08 2023-10-08 08:02:00 Patient Records     Read              Granted        0             10.1.1.15 (Internal) Main Campus - Cardiology Wing 0.00           \n",
            "2023-10-09 2023-10-09 08:05:00 Patient Records     Read              Granted        0             10.1.1.15 (Internal) Main Campus - Cardiology Wing 0.01           \n",
            "2023-10-10 2023-10-10 07:46:00 Patient Records     Read              Granted        0             10.1.1.15 (Internal) Main Campus - Cardiology Wing 0.05           \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset for access"
      ],
      "metadata": {
        "id": "pBy7oSIqzd-R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "from faker import Faker\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Initialize Faker for generating synthetic data\n",
        "fake = Faker()\n",
        "\n",
        "# Define constants with role-department alignment\n",
        "ROLE_DEPARTMENT_MAP = {\n",
        "    \"Doctor\": [\"Emergency\", \"ICU\", \"Radiology\", \"Surgery\", \"Pediatrics\"],\n",
        "    \"Nurse\": [\"Emergency\", \"ICU\", \"Pediatrics\", \"Surgery\"],\n",
        "    \"Receptionist\": [\"Emergency\", \"Records\", \"Admissions\"],\n",
        "    \"Technician\": [\"Radiology\", \"Laboratory\", \"Pharmacy\"],\n",
        "    \"Admin\": [\"Administration\", \"HR\", \"Records\"]\n",
        "}\n",
        "\n",
        "SENSITIVE_ILLNESSES = [\"HIV\", \"Mental Health Disorder\", \"Substance Abuse\", \"Cancer\"]\n",
        "REGULAR_ILLNESSES = [\"Flu\", \"COVID-19\", \"Broken Bone\", \"Infection\", \"Hypertension\", \"Diabetes\"]\n",
        "\n",
        "# Function to generate employee dataset with access levels\n",
        "def generate_employee_dataset(n):\n",
        "    \"\"\"\n",
        "    Generate employee data with role-based access permissions\n",
        "    \"\"\"\n",
        "    data = []\n",
        "    for _ in range(n):\n",
        "        role = random.choice(list(ROLE_DEPARTMENT_MAP.keys()))\n",
        "        department = random.choice(ROLE_DEPARTMENT_MAP[role])\n",
        "\n",
        "        # Define access permissions\n",
        "        permissions = {\n",
        "            \"patient_data\": {\n",
        "                \"access_level\": \"Full\" if role == \"Doctor\" else \"Limited\",\n",
        "                \"allowed_operations\": [\"Read\", \"Update\"] if role == \"Doctor\" else [\"Read\"]\n",
        "            },\n",
        "            \"employee_data\": {\n",
        "                \"access_level\": \"Admin\" if role == \"Admin\" else \"None\",\n",
        "                \"allowed_operations\": [\"Read\", \"Write\", \"Update\"] if role == \"Admin\" else []\n",
        "            }\n",
        "        }\n",
        "\n",
        "        data.append([\n",
        "            f\"E{random.randint(1, 999):03d}\",\n",
        "            fake.name(),\n",
        "            role,\n",
        "            department,\n",
        "            random.randint(50000, 200000),\n",
        "            fake.address().replace(\"\\n\", \", \"),\n",
        "            fake.phone_number(),\n",
        "            permissions\n",
        "        ])\n",
        "\n",
        "    return pd.DataFrame(data, columns=[\n",
        "        \"Employee_ID\", \"Employee_Name\", \"Role\", \"Department\",\n",
        "        \"Salary\", \"Address\", \"Phone\", \"Access_Permissions\"\n",
        "    ])\n",
        "\n",
        "# Function to generate patient dataset with data sensitivity\n",
        "def generate_patient_dataset(n):\n",
        "    \"\"\"\n",
        "    Generate patient data with medical sensitivity levels\n",
        "    \"\"\"\n",
        "    data = []\n",
        "    for _ in range(n):\n",
        "        is_sensitive = random.random() < 0.2  # 20% sensitive cases\n",
        "        illness = random.choice(SENSITIVE_ILLNESSES if is_sensitive else REGULAR_ILLNESSES)\n",
        "\n",
        "        data.append([\n",
        "            f\"P{random.randint(1, 999):03d}\",\n",
        "            fake.name(),\n",
        "            random.choice([\"Male\", \"Female\"]),\n",
        "            random.randint(1, 100),\n",
        "            fake.address().replace(\"\\n\", \", \"),\n",
        "            fake.phone_number(),\n",
        "            illness,\n",
        "            random.choice([\"Private\", \"Medicare\", \"Medicaid\", \"Self-Pay\"]),\n",
        "            datetime.now() - timedelta(days=random.randint(0, 30)),\n",
        "            random.randint(100, 500),\n",
        "            \"High\" if is_sensitive else \"Normal\"\n",
        "        ])\n",
        "\n",
        "    return pd.DataFrame(data, columns=[\n",
        "        \"Patient_ID\", \"Patient_Name\", \"Gender\", \"Age\",\n",
        "        \"Address\", \"Phone\", \"Illness\", \"Insurance_Type\",\n",
        "        \"Admission_Date\", \"Room_Number\", \"Data_Sensitivity\"\n",
        "    ])\n",
        "\n",
        "# Generate datasets\n",
        "employee_df = generate_employee_dataset(20)\n",
        "patient_df = generate_patient_dataset(20)\n",
        "\n",
        "# Display data\n",
        "print(\"\\nEmployee Data (with Access Permissions):\")\n",
        "print(employee_df.head().to_string(index=False))\n",
        "\n",
        "print(\"\\nPatient Data (with Sensitivity Levels):\")\n",
        "print(patient_df.head().to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HM2PXrt1rt6E",
        "outputId": "e7f97eb1-2366-48e0-9fc4-0e3c29816849"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Employee Data (with Access Permissions):\n",
            "Employee_ID  Employee_Name         Role Department  Salary                                                   Address                Phone                                                                                                                                                           Access_Permissions\n",
            "       E285    Noah Rhodes       Doctor    Surgery  168858             600 Jeffery Parkways, New Jamesside, MT 29394     394.802.6542x351                    {'patient_data': {'access_level': 'Full', 'allowed_operations': ['Read', 'Update']}, 'employee_data': {'access_level': 'None', 'allowed_operations': []}}\n",
            "       E380     Ryan Munoz Receptionist  Emergency  143132   161 Calderon River Suite 931, Lake Jeremyport, CO 31013         664-375-2553                           {'patient_data': {'access_level': 'Limited', 'allowed_operations': ['Read']}, 'employee_data': {'access_level': 'None', 'allowed_operations': []}}\n",
            "       E719 Carolyn Daniel        Nurse Pediatrics   68717          8350 Lydia Valley Suite 641, New Nancy, MD 28370 +1-876-772-4238x8496                           {'patient_data': {'access_level': 'Limited', 'allowed_operations': ['Read']}, 'employee_data': {'access_level': 'None', 'allowed_operations': []}}\n",
            "       E176  Zachary Hicks        Admin    Records  190021                 22691 James Mountain, Tashatown, TX 94967         284-651-4627 {'patient_data': {'access_level': 'Limited', 'allowed_operations': ['Read']}, 'employee_data': {'access_level': 'Admin', 'allowed_operations': ['Read', 'Write', 'Update']}}\n",
            "       E474  Pamela Romero        Nurse        ICU  149471 893 Nathaniel Estates Apt. 957, North Sarahport, IA 08093         991.417.1822                           {'patient_data': {'access_level': 'Limited', 'allowed_operations': ['Read']}, 'employee_data': {'access_level': 'None', 'allowed_operations': []}}\n",
            "\n",
            "Patient Data (with Sensitivity Levels):\n",
            "Patient_ID      Patient_Name Gender  Age                                             Address               Phone         Illness Insurance_Type             Admission_Date  Room_Number Data_Sensitivity\n",
            "      P115    Tamara Hampton Female   56  3147 Karen Port Suite 507, Hunterborough, MI 34363  949-948-0831x36783     Broken Bone       Medicare 2025-03-03 10:38:24.346760          101           Normal\n",
            "      P270     Alan Phillips   Male   65         9578 Coleman Summit, Michaelmouth, KY 40690    631-335-1823x374        Diabetes        Private 2025-02-18 10:38:24.347470          420           Normal\n",
            "      P520    Elizabeth Ward   Male   20             0084 Dana Terrace, Garciatown, OK 37769   277.452.0471x1671        Diabetes       Medicaid 2025-02-21 10:38:24.348104          182           Normal\n",
            "      P941     Justin Torres   Male   77                    Unit 1869 Box 9938, DPO AA 59550    649.364.9909x133    Hypertension       Medicaid 2025-03-02 10:38:24.348565          109           Normal\n",
            "      P900 Christopher Jones Female   31 974 Jesse Squares Suite 713, Kristinshire, TN 26429 (918)332-4210x24994 Substance Abuse        Private 2025-03-10 10:38:24.349205          390             High\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "key pattern of historical dataset of one user"
      ],
      "metadata": {
        "id": "rIuf5_7fy_fw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# --- Hugging Face Embedding Model ---\n",
        "def embed_log_entries_hf(df):\n",
        "    \"\"\"Convert log entries to vector embeddings using Hugging Face\"\"\"\n",
        "    model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "\n",
        "    # Create text representations\n",
        "    df['log_text'] = df.apply(\n",
        "        lambda x: f\"On {x['date']} at {x['timestamp'].time()}, \" +\n",
        "                  f\"{static_profile['name']} performed {x['requested_operation']} \" +\n",
        "                  f\"from {x['location']} (IP: {x['ip_address']}), \" +\n",
        "                  f\"MFA failures: {x['mfa_failures']}, \" +\n",
        "                  f\"Risk score: {x['behavior_score']}\",\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    # Generate embeddings\n",
        "    df['embedding'] = df['log_text'].apply(lambda x: model.encode(x))\n",
        "    return df\n",
        "\n",
        "# Generate embeddings\n",
        "embedded_df = embed_log_entries_hf(historical_df.copy())\n",
        "\n",
        "print(\"\\n=== Embedded Log Entries ===\")\n",
        "print(embedded_df[['log_text', 'embedding']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVYP7C8absnO",
        "outputId": "2d83b81e-a90e-476b-ec6f-f36216c7dd53"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Embedded Log Entries ===\n",
            "                                            log_text  \\\n",
            "0  On 2023-10-01 at 08:05:00, Allison Hill perfor...   \n",
            "1  On 2023-10-02 at 07:48:00, Allison Hill perfor...   \n",
            "2  On 2023-10-03 at 07:45:00, Allison Hill perfor...   \n",
            "3  On 2023-10-04 at 08:07:00, Allison Hill perfor...   \n",
            "4  On 2023-10-05 at 08:10:00, Allison Hill perfor...   \n",
            "\n",
            "                                           embedding  \n",
            "0  [-0.029415758, 0.009264707, -0.033427626, 0.02...  \n",
            "1  [-0.031590264, 0.008542097, -0.032836016, 0.02...  \n",
            "2  [-0.029741656, 0.007885972, -0.0342469, 0.0236...  \n",
            "3  [-0.029362421, 0.004619626, -0.030891113, 0.02...  \n",
            "4  [-0.0514411, -0.0012354427, -0.00929477, 0.001...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.docstore.in_memory import InMemoryDocstore\n",
        "from langchain.schema import Document\n",
        "\n",
        "# --- Vector Database with Hugging Face Embeddings ---\n",
        "def create_vector_db_hf(embedded_df):\n",
        "    \"\"\"Store Hugging Face embeddings in a searchable vector database\"\"\"\n",
        "    texts = embedded_df['log_text'].tolist()\n",
        "    embeddings = np.array(embedded_df['embedding'].tolist())\n",
        "\n",
        "    # Create FAISS index\n",
        "    dimension = embeddings.shape[1]  # Get embedding dimension\n",
        "    index = faiss.IndexFlatL2(dimension)  # Create FAISS index\n",
        "    index.add(embeddings.astype('float32'))  # Add embeddings\n",
        "\n",
        "    # Create LangChain FAISS wrapper\n",
        "    vector_db = FAISS(\n",
        "        embedding_function=None,  # Not needed since we have precomputed embeddings\n",
        "        index=index,\n",
        "        docstore=InMemoryDocstore(),\n",
        "        index_to_docstore_id={i: i for i in range(len(texts))}\n",
        "    )\n",
        "\n",
        "    # Add text metadata\n",
        "    for i, text in enumerate(texts):\n",
        "        vector_db.docstore.add({i: Document(page_content=text)})\n",
        "\n",
        "    return vector_db\n",
        "\n",
        "# Create and persist vector DB\n",
        "vector_db = create_vector_db_hf(embedded_df)\n",
        "\n",
        "print(\"\\n=== Vector Database Info ===\")\n",
        "print(f\"Index size: {vector_db.index.ntotal}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6-XndsEbyHg",
        "outputId": "f98ff937-b61e-47ce-c6e3-d1139f560c63"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.vectorstores.faiss:`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Vector Database Info ===\n",
            "Index size: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_access_request(request, vector_db):\n",
        "    \"\"\"Compare real-time request with historical data\"\"\"\n",
        "    model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "\n",
        "    # Create query text\n",
        "    query_text = (\n",
        "        f\"New access request: {request['operation']} operation \"\n",
        "        f\"on {request['dataset']} at {request['time']} \"\n",
        "        f\"from {request['location']} (IP: {request['ip']}), \"\n",
        "        f\"MFA failures: {request['mfa_failures']}\"\n",
        "    )\n",
        "\n",
        "    # Generate query embedding\n",
        "    query_embedding = model.encode(query_text)\n",
        "\n",
        "    # Search FAISS index\n",
        "    distances, indices = vector_db.index.search(\n",
        "        np.array([query_embedding]).astype('float32'),\n",
        "        k=3\n",
        "    )\n",
        "\n",
        "    # Retrieve matching documents\n",
        "    similar_logs = []\n",
        "    for idx in indices[0]:\n",
        "        doc = vector_db.docstore.get(str(idx))\n",
        "        if isinstance(doc, Document):  # Ensure doc is a Document object\n",
        "            similar_logs.append({\n",
        "                'log': doc.page_content,\n",
        "                'score': float(1 - distances[0][idx])  # Convert distance to similarity\n",
        "            })\n",
        "        else:\n",
        "            print(f\"Warning: Retrieved object is not a Document: {doc}\")\n",
        "\n",
        "    return similar_logs"
      ],
      "metadata": {
        "id": "G7Yje91mnQqM"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Simulate Real-Time Request ---\n",
        "def simulate_real_time_request(user_profile, is_suspicious=False):\n",
        "    if is_suspicious:\n",
        "        # Suspicious behavior\n",
        "        request = {\n",
        "            'dataset': 'Patient Records',\n",
        "            'operation': 'Update',\n",
        "            'time': '02:15:00',  # Unusual time\n",
        "            'location': 'External Clinic',  # Unusual location\n",
        "            'ip': '203.0.113.5',  # External IP\n",
        "            'mfa_failures': 2  # Multiple failures\n",
        "        }\n",
        "    else:\n",
        "        # Normal behavior\n",
        "        request = {\n",
        "            'dataset': 'Patient Records',\n",
        "            'operation': 'Read',\n",
        "            'time': '08:10:00',  # Typical time\n",
        "            'location': 'Main Campus - Cardiology Wing',  # Typical location\n",
        "            'ip': '10.1.1.15',  # Internal IP\n",
        "            'mfa_failures': 0  # No failures\n",
        "        }\n",
        "\n",
        "    return request\n",
        "\n",
        "# Simulate a normal request\n",
        "normal_request = simulate_real_time_request(static_profile, is_suspicious=False)\n",
        "\n",
        "# Simulate a suspicious request\n",
        "suspicious_request = simulate_real_time_request(static_profile, is_suspicious=True)\n",
        "\n",
        "# Analyze normal request\n",
        "normal_similar_entries = analyze_access_request(normal_request, vector_db)\n",
        "\n",
        "# Analyze suspicious request\n",
        "suspicious_similar_entries = analyze_access_request(suspicious_request, vector_db)\n",
        "\n",
        "# --- Display Results ---\n",
        "print(\"\\n=== Similar Historical Entries (Normal Request) ===\")\n",
        "for idx, entry in enumerate(normal_similar_entries, 1):\n",
        "    print(f\"\\nMatch #{idx} (Similarity: {entry['score']:.2f}):\")\n",
        "    print(entry['log'])\n",
        "\n",
        "print(\"\\n=== Similar Historical Entries (Suspicious Request) ===\")\n",
        "for idx, entry in enumerate(suspicious_similar_entries, 1):\n",
        "    print(f\"\\nMatch #{idx} (Similarity: {entry['score']:.2f}):\")\n",
        "    print(entry['log'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "66ynQJY1nd-c",
        "outputId": "0d1285bf-a448-4eda-907b-00abf793ac69"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'InMemoryDocstore' object has no attribute 'get'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-d2ee2c961d27>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Analyze normal request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mnormal_similar_entries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalyze_access_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormal_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_db\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# Analyze suspicious request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-20e4f88e7dc4>\u001b[0m in \u001b[0;36manalyze_access_request\u001b[0;34m(request, vector_db)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0msimilar_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvector_db\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocstore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDocument\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Ensure doc is a Document object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             similar_logs.append({\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'InMemoryDocstore' object has no attribute 'get'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simulating User Requests"
      ],
      "metadata": {
        "id": "eOWWR7euuAuz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def simulate_real_time_request(user_profile, is_suspicious=False):\n",
        "    \"\"\"Simulate a real-time access request\"\"\"\n",
        "    if is_suspicious:\n",
        "        # Suspicious behavior\n",
        "        request = {\n",
        "            'dataset': 'Patient Records',\n",
        "            'operation': 'Update',\n",
        "            'time': '02:15:00',  # Unusual time\n",
        "            'location': 'External Clinic',  # Unusual location\n",
        "            'ip': '203.0.113.5',  # External IP\n",
        "            'mfa_failures': 2  # Multiple failures\n",
        "        }\n",
        "    else:\n",
        "        # Normal behavior\n",
        "        request = {\n",
        "            'dataset': 'Patient Records',\n",
        "            'operation': 'Read',\n",
        "            'time': '08:10:00',  # Typical time\n",
        "            'location': 'Main Campus - Cardiology Wing',  # Typical location\n",
        "            'ip': '10.1.1.15',  # Internal IP\n",
        "            'mfa_failures': 0  # No failures\n",
        "        }\n",
        "\n",
        "    return request\n",
        "\n",
        "# Simulate a normal request\n",
        "normal_request = simulate_real_time_request(static_profile, is_suspicious=False)\n",
        "\n",
        "# Simulate a suspicious request\n",
        "suspicious_request = simulate_real_time_request(static_profile, is_suspicious=True)\n",
        "\n",
        "print(\"=== Normal Request ===\")\n",
        "print(normal_request)\n",
        "\n",
        "print(\"\\n=== Suspicious Request ===\")\n",
        "print(suspicious_request)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Euhe5-61uDPJ",
        "outputId": "7a657369-1618-4d3e-c109-b98317eca5e2"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Normal Request ===\n",
            "{'dataset': 'Patient Records', 'operation': 'Read', 'time': '08:10:00', 'location': 'Main Campus - Cardiology Wing', 'ip': '10.1.1.15', 'mfa_failures': 0}\n",
            "\n",
            "=== Suspicious Request ===\n",
            "{'dataset': 'Patient Records', 'operation': 'Update', 'time': '02:15:00', 'location': 'External Clinic', 'ip': '203.0.113.5', 'mfa_failures': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_access_request(request, vector_db):\n",
        "    \"\"\"Compare real-time request with historical data\"\"\"\n",
        "    model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "\n",
        "    # Create query text\n",
        "    query_text = (\n",
        "        f\"New access request: {request['operation']} operation \"\n",
        "        f\"on {request['dataset']} at {request['time']} \"\n",
        "        f\"from {request['location']} (IP: {request['ip']}), \"\n",
        "        f\"MFA failures: {request['mfa_failures']}\"\n",
        "    )\n",
        "\n",
        "    # Generate query embedding\n",
        "    query_embedding = model.encode(query_text)\n",
        "\n",
        "    # Search FAISS index\n",
        "    distances, indices = vector_db.index.search(\n",
        "        np.array([query_embedding]).astype('float32'),\n",
        "        k=3\n",
        "    )\n",
        "\n",
        "    # Retrieve matching documents\n",
        "    similar_logs = []\n",
        "    for idx in indices[0]:\n",
        "        # Access the document directly using dictionary-like syntax or search\n",
        "        # doc = vector_db.docstore[idx]  # if IDs are integers and sequential\n",
        "        doc = vector_db.docstore.search(str(idx)) # Use search for more general cases\n",
        "\n",
        "        if isinstance(doc, Document):  # Ensure doc is a Document object\n",
        "            similar_logs.append({\n",
        "                'log': doc.page_content,\n",
        "                'score': float(1 - distances[0][idx])  # Convert distance to similarity\n",
        "            })\n",
        "        else:\n",
        "            print(f\"Warning: Retrieved object is not a Document: {doc}\")\n",
        "\n",
        "    return similar_logs"
      ],
      "metadata": {
        "id": "q7RQ0OSqmLYp"
      },
      "execution_count": 36,
      "outputs": []
    }
  ]
}